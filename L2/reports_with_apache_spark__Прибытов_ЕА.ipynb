{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_H0ej2xvBto",
        "outputId": "f239222d-e079-47e1-b43f-f89d5a621b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connecting to r2u.\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "--2025-04-18 08:56:57--  https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228721937 (218M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.1.1-bin-hadoop3.2.tgz.3’\n",
            "\n",
            "spark-3.1.1-bin-had 100%[===================>] 218.13M  19.0MB/s    in 13s     \n",
            "\n",
            "2025-04-18 08:57:10 (17.4 MB/s) - ‘spark-3.1.1-bin-hadoop3.2.tgz.3’ saved [228721937/228721937]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Java\n",
        "!apt-get update # Обновляем список пакетов в системе\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Устанавливаем OpenJDK 8 (Java Development Kit) без графического интерфейса\n",
        "# > /dev/null: Перенаправляет вывод команды в /dev/null (пустое устройство), чтобы скрыть вывод в консоли\n",
        "\n",
        "# Spark\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Загружаем архив Spark 3.1.1, предварительно скомпилированный для Hadoop 3.2, с сайта Apache\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Распаковываем архив"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1FlXARTFyoyO"
      },
      "outputs": [],
      "source": [
        "# настраеваем переменные окружения\n",
        "import os  # Импортирует модуль для работы с операционной системой\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"  # Устанавливает переменную окружения JAVA_HOME\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\" # Устанавливает переменную окружения SPARK_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vrbs-JZXytIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60de345c-857c-4901-cff8-97f379aeb931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Устанавливаем findspark\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "import findspark\n",
        "findspark.init() # Инициализируем findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbGyPj-s2KhA"
      },
      "source": [
        "**Проверка установки. Инициализация сессии, импорт необходимых библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvc6T3562G2G",
        "outputId": "061604ba-7775-4926-e96a-705853b7273d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1.1\n"
          ]
        }
      ],
      "source": [
        "# Создание SparkContext (проверка установки)\n",
        "import re\n",
        "from pyspark.sql.functions import udf, col, year, lit, when, explode, regexp_replace, lower, split, rank\n",
        "from typing import List\n",
        "# Создание SparkContext\n",
        "from pyspark import SparkContext, SparkConf\n",
        "import pyspark.sql as sql\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DoubleType, IntegerType, ArrayType, StringType\n",
        "from pyspark.sql.functions import max, sum, countDistinct, desc\n",
        "\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"L2_reports_with_apache_spark\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.databricks:spark-xml_2.12:0.13.0\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext# Получаем SparkContext из SparkSession, SparkContext - это точка входа в Spark\n",
        "\n",
        "print(sc.version)  # Выводим версию Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rst_W-uc2fCi"
      },
      "source": [
        "**Загрузка данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw74DHRh6Au7",
        "outputId": "32e4a5cd-6ec8-4228-d7a0-a3e1eeed6468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posts\n",
            "root\n",
            " |-- _AcceptedAnswerId: long (nullable = true)\n",
            " |-- _AnswerCount: long (nullable = true)\n",
            " |-- _Body: string (nullable = true)\n",
            " |-- _ClosedDate: timestamp (nullable = true)\n",
            " |-- _CommentCount: long (nullable = true)\n",
            " |-- _CommunityOwnedDate: timestamp (nullable = true)\n",
            " |-- _CreationDate: timestamp (nullable = true)\n",
            " |-- _FavoriteCount: long (nullable = true)\n",
            " |-- _Id: long (nullable = true)\n",
            " |-- _LastActivityDate: timestamp (nullable = true)\n",
            " |-- _LastEditDate: timestamp (nullable = true)\n",
            " |-- _LastEditorDisplayName: string (nullable = true)\n",
            " |-- _LastEditorUserId: long (nullable = true)\n",
            " |-- _OwnerDisplayName: string (nullable = true)\n",
            " |-- _OwnerUserId: long (nullable = true)\n",
            " |-- _ParentId: long (nullable = true)\n",
            " |-- _PostTypeId: long (nullable = true)\n",
            " |-- _Score: long (nullable = true)\n",
            " |-- _Tags: string (nullable = true)\n",
            " |-- _Title: string (nullable = true)\n",
            " |-- _ViewCount: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "posts_data = spark.read\\\n",
        ".format('xml')\\\n",
        ".options(rowTag='row')\\\n",
        ".load('posts_sample.xml')\n",
        "print(\"Posts\")\n",
        "posts_data.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4-Xben4Axbq"
      },
      "source": [
        "# Задание\n",
        "\n",
        "Задание: Сформировать отчёт с информацией о 10 наиболее популярных языках программирования по итогам года за период с 2010 по 2020 годы. Отчёт будет отражать динамику изменения популярности языков программирования и представлять собой набор таблиц \"топ-10\" для каждого года.\n",
        "\n",
        "Получившийся отчёт сохранить в формате Apache Parquet."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считываем programming-languages.csv\n",
        "langs_df = spark.read.option(\"header\", True).csv(\"programming-languages.csv\")\n",
        "langs_list = [row[\"name\"].lower() for row in langs_df.select(\"name\").distinct().collect()]# Преобразуем названия языков в список\n",
        "langs_broadcast = spark.sparkContext.broadcast(langs_list)# Распространяем список языков на все узлы кластера\n"
      ],
      "metadata": {
        "id": "jnYt6oU_GWKh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обработка тегов и извлечение года\n",
        "# 1. Удаляем угловые скобки из тегов и разделяем строку тегов в массив\n",
        "# 2. Извлекаем год из даты последней активности поста\n",
        "# 3. Выбираем только нужные столбцы и переименовываем _ViewCount\n",
        "posts_data = posts_data.withColumn(\"tags\", split(regexp_replace(col(\"_Tags\"), \"[<>]\", \",\"), \",\")) \\\n",
        "                   .withColumn(\"year\", year(col(\"_LastActivityDate\"))) \\\n",
        "                   .select(\"tags\", \"year\", \"_ViewCount\") \\\n",
        "                   .withColumnRenamed(\"_ViewCount\", \"views\")"
      ],
      "metadata": {
        "id": "davzu2EqGX90"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разворачивание массива тегов в отдельные строки\n",
        "tags_df = posts_data.withColumn(\"tag\", explode(col(\"tags\"))).select(\"tag\", \"year\", \"views\")\n",
        "filtered_tags = tags_df.filter(lower(col(\"tag\")).isin(langs_broadcast.value))# Фильтрация по языкам программирования\n",
        "\n",
        "# Группировка по году и языку и считаем суммарное количество просмотров\n",
        "views_by_lang = filtered_tags.groupBy(\"year\", \"tag\").agg(sum(\"views\").alias(\"total_views\")) \\\n",
        "                             .filter((col(\"year\") >= 2010) & (col(\"year\") <= 2020))\n"
      ],
      "metadata": {
        "id": "wTaLVCawGdM5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление ранга в пределах каждого года — 1 место имеет больше всего просмотров\n",
        "ranking = views_by_lang.withColumn(\n",
        "    \"rank\",\n",
        "    rank().over(Window.partitionBy(\"year\").orderBy(col(\"total_views\").desc()))\n",
        ")\n",
        "\n",
        "# Выбираем 10 самых используемых языков на каждый год\n",
        "top_10_by_year = ranking.filter(col(\"rank\") <= 10) \\\n",
        "                        .select(\"year\", \"tag\", \"total_views\") \\\n",
        "                        .orderBy(\"year\", col(\"total_views\").desc())\n",
        "\n",
        "# Сохраняем итоговый DataFrame в формате Parquet\n",
        "top_10_by_year.write.mode(\"overwrite\").parquet(\"popular_languages_top10.parquet\")\n",
        "\n",
        "# Отображаем результат — топ-10 языков для каждого года\n",
        "top_10_by_year.show(50, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx07dhwe_tOJ",
        "outputId": "d4ed02a6-e4a7-4a4d-c85f-5007b7e33bce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-----------+\n",
            "|year|tag        |total_views|\n",
            "+----+-----------+-----------+\n",
            "|2010|java       |53333      |\n",
            "|2010|matlab     |51865      |\n",
            "|2010|objective-c|43878      |\n",
            "|2010|php        |39730      |\n",
            "|2010|javascript |37059      |\n",
            "|2010|python     |25930      |\n",
            "|2010|ruby       |15864      |\n",
            "|2010|c          |13810      |\n",
            "|2010|delphi     |7680       |\n",
            "|2010|r          |7499       |\n",
            "|2011|java       |121315     |\n",
            "|2011|python     |89637      |\n",
            "|2011|c          |73116      |\n",
            "|2011|php        |67341      |\n",
            "|2011|javascript |61631      |\n",
            "|2011|objective-c|54815      |\n",
            "|2011|r          |14394      |\n",
            "|2011|ruby       |9771       |\n",
            "|2011|cython     |8109       |\n",
            "|2011|delphi     |6724       |\n",
            "|2012|php        |303789     |\n",
            "|2012|java       |272219     |\n",
            "|2012|python     |220014     |\n",
            "|2012|javascript |204780     |\n",
            "|2012|objective-c|50825      |\n",
            "|2012|bash       |36183      |\n",
            "|2012|ruby       |32695      |\n",
            "|2012|c          |31552      |\n",
            "|2012|delphi     |16898      |\n",
            "|2012|lua        |13984      |\n",
            "|2013|javascript |500317     |\n",
            "|2013|java       |343064     |\n",
            "|2013|php        |213325     |\n",
            "|2013|python     |132913     |\n",
            "|2013|objective-c|82000      |\n",
            "|2013|ruby       |70638      |\n",
            "|2013|c          |31911      |\n",
            "|2013|r          |31325      |\n",
            "|2013|matlab     |24371      |\n",
            "|2013|go         |19262      |\n",
            "|2014|java       |335778     |\n",
            "|2014|javascript |315136     |\n",
            "|2014|php        |203884     |\n",
            "|2014|python     |81682      |\n",
            "|2014|c          |59396      |\n",
            "|2014|objective-c|58272      |\n",
            "|2014|ruby       |57699      |\n",
            "|2014|r          |43673      |\n",
            "|2014|scala      |25311      |\n",
            "|2014|delphi     |20824      |\n",
            "+----+-----------+-----------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}